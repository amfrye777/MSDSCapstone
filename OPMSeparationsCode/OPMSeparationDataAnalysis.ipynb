{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPM Data Separation Analysis\n",
    "<i><b>\n",
    "Christopher Boomhower<sub>1</sub>, Stacey Fabricant<sub>2</sub>, Alex Frye<sub>1</sub>, David Mumford<sub>2</sub>, Michael Smith<sub>1</sub>, Lindsay Vitovsky<sub>1</sub>\n",
    "\n",
    "<sub>1</sub> Southern Methodis Univeristy, Dallas, TX, US\n",
    "<sub>2</sub> Penn Mutual Life Insurance Co, Horsham PA\n",
    "</i></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "background text...\n",
    "\n",
    "**our intent is to: 1)..2)...3)........**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "Data Source Background Text & citation links\n",
    "\n",
    "Dataset Attribute Descriptions\n",
    "(e.g. 1. **tripduration** - *Integer* - The total tim....)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "\n",
    "text intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import missingno as msno\n",
    "import prettytable\n",
    "import math\n",
    "\n",
    "## Library Options\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pre-defined Functions for use later\n",
    "def pickleObject(objectname, filename, filepath = \"PickleJar/\"):\n",
    "    fullpicklepath = \"{0}{1}.pkl\".format(filepath, filename)\n",
    "    # Create a variable to pickle and open it in write mode\n",
    "    picklefile = open(fullpicklepath, 'wb')\n",
    "    pickle.dump(objectname, picklefile)\n",
    "    picklefile.close()\n",
    "    \n",
    "def unpickleObject(filename, filepath = \"PickleJar/\"):\n",
    "    fullunpicklepath = \"{0}{1}.pkl\".format(filepath, filename)\n",
    "    # Create an variable to pickle and open it in write mode\n",
    "    unpicklefile = open(fullunpicklepath, 'rb')\n",
    "    unpickleObject = pickle.load(unpicklefile)\n",
    "    unpicklefile.close()\n",
    "\n",
    "    return unpickleObject\n",
    "    \n",
    "def clear_display():\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "## Pre-defined variables for use later\n",
    "dataOPMPath = \"dataOPM\"\n",
    "dataEMPPath = \"dataEMP\"\n",
    "PickleJarPath = \"PickleJar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Load OPMSeparation Files\n",
    "\n",
    "OPMDataFiles = glob.glob(os.path.join(dataOPMPath, \"*.txt\"))\n",
    "\n",
    "for i in range(0,len(OPMDataFiles)):\n",
    "    OPMDataFiles[i] = OPMDataFiles[i].replace(\"\\\\\",\"/\")\n",
    "\n",
    "OPMDataList = []\n",
    "\n",
    "for i,j in zip(OPMDataFiles,range(0,len(OPMDataFiles))):\n",
    "    OPMDataList.append(pd.read_csv(i, dtype = 'str'))\n",
    "    display(OPMDataList[j].head())\n",
    "\n",
    "## Load the SEPDATA_FY2015 file into it's own object\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/SEPDATA_FY2015.txt']\n",
    "OPMDataOrig = OPMDataList[indexes[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#print(OPMDataFiles)\n",
    "\n",
    "print(len(OPMDataOrig))\n",
    "\n",
    "##### Merge / Modify Codes / Aggregate Attributes to be more descriptive per the metadata files\n",
    "\n",
    "OPMDataMerged = OPMDataOrig.copy()\n",
    "\n",
    "##AGYSUB - AGYTYP, AGY\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTagy.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'AGYSUB', how = 'left')\n",
    "\n",
    "##EFDate - quarter, month\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTefdate.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'EFDATE', how = 'left')\n",
    "\n",
    "##AGELVL - AGELVLT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTagelvl.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'AGELVL', how = 'left')\n",
    "\n",
    "##LOSLVL - LOSLVLT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTloslvl.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'LOSLVL', how = 'left')\n",
    "\n",
    "##LOC - LocTypeT, LocT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTloc.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'LOC', how = 'left')\n",
    "\n",
    "##OCC - OCCTYPT, OCCFAM\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTocc.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'OCC', how = 'left')\n",
    "\n",
    "##PATCO - PATCOT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTpatco.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'PATCO', how = 'left')\n",
    "\n",
    "##PPGRD - PayPlan, PPGroup, PPTYP\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTppgrd.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'PPGRD', how = 'left')\n",
    "\n",
    "##SALLVL - SALLVLT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTsallvl.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'SALLVL', how = 'left')\n",
    "\n",
    "##TOA - TOATYP\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTtoa.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'TOA', how = 'left')\n",
    "\n",
    "##WORKSCH - WSTYPT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTwrksch.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'WORKSCH', how = 'left')\n",
    "\n",
    "\n",
    "## Modify Data Types for numeric objects\n",
    "OPMDataMerged[\"SALARY\"] = OPMDataMerged[\"SALARY\"].apply(pd.to_numeric)\n",
    "OPMDataMerged[\"COUNT\"]  = OPMDataMerged[\"COUNT\"].apply(pd.to_numeric)\n",
    "OPMDataMerged[\"LOS\"]    = OPMDataMerged[\"LOS\"].apply(pd.to_numeric)\n",
    "\n",
    "## Remove Non-US Data\n",
    "OPMDataMerged = OPMDataMerged[OPMDataMerged[\"LOCTYP\"] == \"1\"]\n",
    "\n",
    "   ## Remove Observations with no specified occupation\n",
    "OPMDataMerged = OPMDataMerged[OPMDataMerged[\"OCCTYP\"] != \"3\"]\n",
    "\n",
    "   ## Remove Observations with no specified salary\n",
    "OPMDataMerged = OPMDataMerged[OPMDataMerged[\"SALLVL\"] != \"Z\"]\n",
    "\n",
    "   ## Remove Observations with no specified salary\n",
    "OPMDataMerged = OPMDataMerged[OPMDataMerged[\"LOSLVL\"] != \"Z\"]\n",
    "\n",
    "display(OPMDataMerged.head())\n",
    "display(OPMDataMerged.describe().transpose())\n",
    "#del OPMDataList,OPMDataFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isfile(PickleJarPath+\"/EMPDataOrig4Q.pkl\"):\n",
    "    print(\"Found the File! Loading Pickle Now!\")\n",
    "    EMPDataOrig4Q = unpickleObject(\"EMPDataOrig4Q\")\n",
    "else:\n",
    "    ## Load EMPData Files\n",
    "\n",
    "    indexes = []\n",
    "    EMPDataFiles = []\n",
    "    EMPDataList = []\n",
    "    EMPDataOrig = []\n",
    "\n",
    "    for i,qtr in enumerate([\"Q1\", \"Q2\", \"Q3\", \"Q4\"]): \n",
    "        EMPDataFiles.append(glob.glob(os.path.join(dataEMPPath, qtr + \"/*.txt\")))\n",
    "\n",
    "        for j in range(0,len(EMPDataFiles[i])):\n",
    "            EMPDataFiles[i][j] = EMPDataFiles[i][j].replace(\"\\\\\",\"/\")\n",
    "\n",
    "        EMPDataList.append([])\n",
    "\n",
    "        for j,file in enumerate(EMPDataFiles[i]):\n",
    "            EMPDataList[i].append(pd.read_csv(file, dtype = 'str'))\n",
    "            if i == 0:\n",
    "                display(EMPDataList[i][j].head())\n",
    "\n",
    "        ## Load the FactData files into it's own object\n",
    "        indexes.append([])\n",
    "            ##[qtr][fileindex from EMPDataList]\n",
    "        indexes[i]=[j for j,x in enumerate(EMPDataFiles[i]) if dataEMPPath + '/' + qtr + '/FACTDATA' in x]   \n",
    "\n",
    "        EMPDataOrig.append([])\n",
    "\n",
    "        EMPDataOrig[i] = pd.concat([EMPDataList[i][indexes[i][j]] for j in range(0,len(indexes[i]))]) \n",
    "        EMPDataOrig[i][\"QTR\"] = str(i+1)\n",
    "\n",
    "            ## modify data type for numerics\n",
    "        EMPDataOrig[i][\"SALARY\"] = EMPDataOrig[i][\"SALARY\"].str.replace(',', '').str.replace('$', '').str.replace(' ', '').apply(pd.to_numeric)\n",
    "      \n",
    "        ## Load Metadata\n",
    "        ##AGYSUB - AGYTYP, AGY\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTagy.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'AGYSUB', how = 'left')\n",
    "\n",
    "        ##AGELVL - AGELVLT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTagelvl.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'AGELVL', how = 'left')\n",
    "\n",
    "        #LOSLVL - LOSLVLT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTloslvl.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'LOSLVL', how = 'left')\n",
    "        EMPDataOrig[i][\"LOS\"] = EMPDataOrig[i][\"LOS\"].apply(pd.to_numeric)\n",
    "        \n",
    "        ##LOC - LocTypeT, LocT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTloc.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'LOC', how = 'left')\n",
    " \n",
    "        ##OCC - OCCTYPT, OCCFAM\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTocc.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'OCC', how = 'left')\n",
    "\n",
    "        ##PATCO - PATCOT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTpatco.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'PATCO', how = 'left')\n",
    "\n",
    "        ##PPGRD - PayPlan, PPGroup, PPTYP\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTppgrd.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'PPGRD', how = 'left')\n",
    "\n",
    "        ##SALLVL - SALLVLT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTsallvl.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'SALLVL', how = 'left')\n",
    "\n",
    "        ##TOA - TOATYP\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTtoa.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'TOA', how = 'left')\n",
    "\n",
    "        ##WORKSCH - WSTYPT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTwrksch.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'WORKSCH', how = 'left')\n",
    "\n",
    "        display(EMPDataOrig[i].head())\n",
    "\n",
    "    EMPDataOrig4Q = pd.concat([EMPDataOrig[j] for j in range(0,len(EMPDataOrig))])\n",
    "    \n",
    "       ## Remove Non-US Data\n",
    "    EMPDataOrig4Q = EMPDataOrig4Q[EMPDataOrig4Q[\"LOCTYP\"] == \"1\"]\n",
    "    \n",
    "       ## Remove Observations with no specified occupation\n",
    "    EMPDataOrig4Q = EMPDataOrig4Q[EMPDataOrig4Q[\"OCCTYP\"] != \"3\"]\n",
    "\n",
    "       ## Remove Observations with no specified salary\n",
    "    EMPDataOrig4Q = EMPDataOrig4Q[EMPDataOrig4Q[\"SALLVL\"] != \"Z\"]\n",
    "    \n",
    "       ## Remove Observations with no specified salary\n",
    "    EMPDataOrig4Q = EMPDataOrig4Q[EMPDataOrig4Q[\"LOSLVL\"] != \"Z\"]\n",
    "\n",
    "    pickleObject(EMPDataOrig4Q, \"EMPDataOrig4Q\")\n",
    "\n",
    "print(len(EMPDataOrig4Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(EMPDataOrig4Q.describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.boxplot(y = \"SALARY\", data = EMPDataOrig4Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "##Aggregate Number of Total Separations in current month for given Occ\n",
    "AggSEPCount_EFDATE_OCC= pd.DataFrame({'SEPCount_EFDATE_OCC' : OPMDataMerged.groupby([\"EFDATE\", \"OCC\"]).size()}).reset_index()\n",
    "display(AggSEPCount_EFDATE_OCC.head())\n",
    "\n",
    "\n",
    "##Aggregate Number of Total Separations in current month for given LOC\n",
    "AggSEPCount_EFDATE_LOC = pd.DataFrame({'SEPCount_EFDATE_LOC' : OPMDataMerged.groupby([\"EFDATE\", \"LOC\"]).size()}).reset_index()\n",
    "display(AggSEPCount_EFDATE_LOC.head())\n",
    "\n",
    "##Average Quarterly EMP Salary by occ \n",
    "AggIndAvgSalary = pd.DataFrame({'count' : EMPDataOrig4Q.groupby([\"QTR\", \"OCC\", \"PPGRD\", \"WORKSCHT\"]).size()}).reset_index()\n",
    "AggIndAvgSalary2 = pd.DataFrame({'IndSalarySum' : EMPDataOrig4Q.groupby([\"QTR\", \"OCC\", \"PPGRD\", \"WORKSCHT\"])[\"SALARY\"].sum()}).reset_index()\n",
    "AggIndAvgSalary = AggIndAvgSalary.merge(AggIndAvgSalary2,on=[\"QTR\", \"OCC\", \"PPGRD\", \"WORKSCHT\"])\n",
    "AggIndAvgSalary[\"IndAvgSalary\"] = AggIndAvgSalary[\"IndSalarySum\"]/AggIndAvgSalary[\"count\"]\n",
    "del AggIndAvgSalary[\"count\"]\n",
    "del AggIndAvgSalary[\"IndSalarySum\"]\n",
    "display(AggIndAvgSalary.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Two Datasets\n",
    "### NS SEP code means NonSeparation\n",
    "###add hardcoded null value columns where applicable\n",
    "EMPDataOrig4Q[\"SEP\"] = \"NS\"\n",
    "EMPDataOrig4Q[\"GENDER\"] = np.nan\n",
    "EMPDataOrig4Q[\"COUNT\"] = np.nan\n",
    "\n",
    "OPMDataMerged[\"DATECODE\"] = OPMDataMerged[\"EFDATE\"]\n",
    "\n",
    "OPMColList = [\"AGYSUB\", \"SEP\", \"DATECODE\",   \"AGELVL\", \"GENDER\", \"GSEGRD\", \"LOSLVL\", \"LOC\", \"OCC\", \"PATCO\", \"PPGRD\", \"SALLVL\", \"TOA\", \"WORKSCH\", \"COUNT\", \"SALARY\", \"LOS\", \"AGYTYP\", \"AGYTYPT\", \"AGY\", \"AGYT\", \"AGYSUBT\", \"QTR\", \"AGELVLT\", \"LOSLVLT\", \"LOCTYP\", \"LOCTYPT\", \"LOCT\", \"OCCTYP\", \"OCCTYPT\", \"OCCFAM\", \"OCCFAMT\", \"OCCT\", \"PATCOT\", \"PPTYP\", \"PPTYPT\", \"PPGROUP\", \"PPGROUPT\", \"PAYPLAN\", \"PAYPLANT\", \"SALLVLT\", \"TOATYP\", \"TOATYPT\", \"TOAT\", \"WSTYP\", \"WSTYPT\", \"WORKSCHT\"]\n",
    "EMPColList = [\"AGYSUB\", \"SEP\", \"DATECODE\", \"AGELVL\", \"GENDER\", \"GSEGRD\", \"LOSLVL\", \"LOC\", \"OCC\", \"PATCO\", \"PPGRD\", \"SALLVL\", \"TOA\", \"WORKSCH\", \"COUNT\", \"SALARY\", \"LOS\", \"AGYTYP\", \"AGYTYPT\", \"AGY\", \"AGYT\", \"AGYSUBT\", \"QTR\", \"AGELVLT\", \"LOSLVLT\", \"LOCTYP\", \"LOCTYPT\", \"LOCT\", \"OCCTYP\", \"OCCTYPT\", \"OCCFAM\", \"OCCFAMT\", \"OCCT\", \"PATCOT\", \"PPTYP\", \"PPTYPT\", \"PPGROUP\", \"PPGROUPT\", \"PAYPLAN\", \"PAYPLANT\", \"SALLVLT\", \"TOATYP\", \"TOATYPT\", \"TOAT\", \"WSTYP\", \"WSTYPT\", \"WORKSCHT\"]\n",
    "\n",
    "OPMDataMerged = pd.concat([OPMDataMerged[OPMColList], EMPDataOrig4Q[EMPColList]], ignore_index=True)\n",
    "\n",
    "\n",
    "OPMDataMerged = OPMDataMerged.merge(AggSEPCount_EFDATE_OCC, left_on = ['DATECODE','OCC'], right_on = ['EFDATE','OCC'], how = 'left')\n",
    "OPMDataMerged = OPMDataMerged.merge(AggSEPCount_EFDATE_LOC, left_on = ['DATECODE','LOC'], right_on = ['EFDATE','LOC'], how = 'left')\n",
    "OPMDataMerged = OPMDataMerged.merge(AggIndAvgSalary, on = ['QTR','OCC', 'PPGRD', 'WORKSCHT'], how = 'left')\n",
    "OPMDataMerged[\"SalaryOverUnderIndAvg\"] = OPMDataMerged[\"SALARY\"] - OPMDataMerged[\"IndAvgSalary\"]\n",
    "\n",
    "del OPMDataMerged[\"EFDATE_x\"]\n",
    "del OPMDataMerged[\"EFDATE_y\"]\n",
    "\n",
    "display(OPMDataMerged.head())\n",
    "display(OPMDataMerged.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(AggIndAvgSalary[(AggIndAvgSalary[\"QTR\"]==\"4\")\n",
    "#                        & (AggIndAvgSalary[\"OCC\"]==\"0905\")\n",
    "#                        & (AggIndAvgSalary[\"PPGRD\"]==\"GS-11\")\n",
    "#                        & (AggIndAvgSalary[\"WORKSCHT\" == \"F-Full-time Nonseasonal\"])])\n",
    "\n",
    "print(len(OPMDataMerged[OPMDataMerged[\"IndAvgSalary\"].isnull()]))\n",
    "\n",
    "display(OPMDataMerged[OPMDataMerged[\"IndAvgSalary\"].isnull()][[\"SEP\",\"OCCT\", \"PPGRD\", \"WORKSCHT\"]].drop_duplicates())\n",
    "\n",
    "#filtered_msnoData = msno.nullity_sort(msno.nullity_filter(OPMDataMerged, filter='bottom', n=15, p=0.999), sort='descending')\n",
    "#msno.matrix(filtered_msnoData)\n",
    "\n",
    "#del filtered_msnoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Column YearsToRetirement\n",
    "\n",
    "\n",
    "\n",
    "display(OPMDataMerged.head())\n",
    "display(OPMDataMerged.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Bureau of Labor Statistics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def bls(series, start, end):\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    sID   = []\n",
    "    \n",
    "    for i in range(0,len(series)):\n",
    "        sID.append(series[i][0])\n",
    "    \n",
    "    data = json.dumps({\"seriesid\": sID,\n",
    "                       \"startyear\":start,\n",
    "                       \"endyear\":end,\n",
    "                       \"catalog\":False,\n",
    "                       \"calculations\":False,\n",
    "                       \"annualaverage\":False,\n",
    "                       \"registrationkey\":\"7a89c8d7979349fba8914b8be16a1646\"})\n",
    "    \n",
    "    p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "    json_data = json.loads(p.text)\n",
    "    bls = []\n",
    "    for series in json_data['Results']['series']:\n",
    "        #x=prettytable.PrettyTable([\"series id\",\"year\",\"period\",\"value\",\"footnotes\"])\n",
    "        result = pd.DataFrame(columns=[\"series id\",\"year\",\"period\",\"value\",\"footnotes\"])\n",
    "        seriesId = series['seriesID']\n",
    "        for item in series['data']:\n",
    "            year = item['year']\n",
    "            period = item['period']\n",
    "            value = item['value']\n",
    "            footnotes=\"\"\n",
    "            for footnote in item['footnotes']:\n",
    "                if footnote:\n",
    "                    footnotes = footnotes + footnote['text'] + ','\n",
    "            if 'M01' <= period <= 'M12':\n",
    "                #x.add_row([seriesId,year,period,value,footnotes[0:-1]])\n",
    "                y = pd.DataFrame({\"series id\" : seriesId,\n",
    "                                  \"year\" : year,\n",
    "                                  \"period\" : period,\n",
    "                                  \"value\" : value,\n",
    "                                  \"footnotes\" : footnotes}, index = [0])\n",
    "                result = result.append(y, ignore_index = True)\n",
    "        bls.append(result)\n",
    "    return(bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seriesList = [\n",
    "              ['JTU91000000JOL','BLS_FEDERAL_JobOpenings_Level'],\n",
    "              ['JTU91000000LDL','BLS_FEDERAL_Layoffs_Level'],\n",
    "              ['JTU91000000OSL','BLS_FEDERAL_OtherSep_Level'],\n",
    "              ['JTU91000000QUL','BLS_FEDERAL_Quits_Level'],\n",
    "              ['JTU91000000TSL','BLS_FEDERAL_TotalSep_Level'],\n",
    "              ['JTU91000000JOR','BLS_FEDERAL_JobOpenings_Rate'],\n",
    "              ['JTU91000000LDR','BLS_FEDERAL_Layoffs_Rate'],\n",
    "              ['JTU91000000OSR','BLS_FEDERAL_OtherSep_Rate'],\n",
    "              ['JTU91000000QUR','BLS_FEDERAL_Quits_Rate'],\n",
    "              ['JTU91000000TSR','BLS_FEDERAL_TotalSep_Rate']\n",
    "             ]\n",
    "\n",
    "# Pull job openings and labor turnover data\n",
    "JTL = bls(seriesList, \"2014\", \"2015\")\n",
    "\n",
    "seriesList = pd.DataFrame(seriesList, columns = [\"series id\",\"sName\"])\n",
    "\n",
    "##We need to replace these with actual Descriptor Column Names\n",
    "\n",
    "for i in range(0,len(seriesList)):\n",
    "    \n",
    "    JTL[i] = JTL[i].merge(seriesList, on = \"series id\", how = 'inner')\n",
    "\n",
    "    if len(JTL[i]) >0:\n",
    "        name = JTL[i][\"sName\"].drop_duplicates().values[0]\n",
    "    else:\n",
    "        name = str(i)\n",
    "\n",
    "    JTL[i][name] = JTL[i][\"value\"].apply(pd.to_numeric)\n",
    "    JTL[i][\"DATECODE\"] = JTL[i][\"year\"] + JTL[i][\"period\"].str[-2:]\n",
    "    del JTL[i][\"value\"]\n",
    "    del JTL[i][\"year\"]\n",
    "    del JTL[i][\"period\"]\n",
    "    del JTL[i][\"series id\"]\n",
    "    del JTL[i][\"footnotes\"]\n",
    "    del JTL[i][\"sName\"]\n",
    "    \n",
    "    \n",
    "    OPMDataMerged = OPMDataMerged.merge(JTL[i], on = \"DATECODE\", how = 'left')\n",
    "    display(JTL[i].head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(OPMDataMerged.head())\n",
    "display(OPMDataMerged.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame({'StratCount' : OPMDataMerged.groupby([\"SEP\"]).size()}).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roll Up / Remove Separation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OPMDataMerged = OPMDataMerged[(OPMDataMerged[\"SEP\"] != \"SB\") & (OPMDataMerged[\"SEP\"] != \"SK\") & (OPMDataMerged[\"SEP\"] != \"SL\")]\n",
    "\n",
    "OPMDataMerged.loc[(OPMDataMerged[\"SEP\"] == \"SD\") | (OPMDataMerged[\"SEP\"] == \"SE\") | (OPMDataMerged[\"SEP\"] == \"SF\") | (OPMDataMerged[\"SEP\"] == \"SG\"), \"SEP\"]=\"SD\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratum = pd.DataFrame({'StratCount' : OPMDataMerged.groupby([\"SEP\"]).size()}).reset_index()\n",
    "\n",
    "stratum.loc[stratum[\"StratCount\"]>50000,\"StratCountSample\"] = 50000\n",
    "stratum.loc[stratum[\"StratCount\"]<=50000,\"StratCountSample\"] = stratum[\"StratCount\"]\n",
    "#else: stratum[\"StratCountSample\"] = stratum[\"StratCount\"]\n",
    "\n",
    "display(stratum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MaxSampleSize = 50000\n",
    "\n",
    "AggStrat = []\n",
    "\n",
    "for i in range(0,len(stratum)):\n",
    "    sep = stratum[\"SEP\"].ix[i]\n",
    "    StratCountSample = stratum[\"StratCountSample\"].ix[i]\n",
    "    print(\"Stratum Sample Size Calculations for SEP: {}\".format(sep))   \n",
    "    AggStrat.append(pd.DataFrame({'StratCount' : OPMDataMerged[OPMDataMerged[\"SEP\"]==sep].groupby([\"DATECODE\", \"AGELVL\"]).size()}).reset_index())\n",
    "    AggStrat[i][\"SEP\"] = sep\n",
    "    AggStrat[i][\"TotalCount\"] = len(OPMDataMerged[OPMDataMerged[\"SEP\"]==sep])\n",
    "    AggStrat[i][\"p\"] = AggStrat[i][\"StratCount\"] / AggStrat[i][\"TotalCount\"]\n",
    "    AggStrat[i][\"StratCountSample\"] = StratCountSample\n",
    "    AggStrat[i][\"StratSampleSize\"] = round(AggStrat[i][\"p\"] * StratCountSample).apply(int)\n",
    "    \n",
    "    display(AggStrat[i].head())\n",
    "    print(\"totalStratumSampleSize: \", AggStrat[i][\"StratSampleSize\"].sum())\n",
    "    #print(len(AggStrat[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if os.path.isfile(PickleJarPath+\"/SampledOPMData.pkl\"):\n",
    "    print(\"Found the File! Loading Pickle Now!\")\n",
    "    SampledOPMData = unpickleObject(\"SampledOPMData\")\n",
    "else:\n",
    "    SampledOPMStratumDataList = []\n",
    "\n",
    "    for i,StratSampleSize in enumerate(AggStrat):\n",
    "        SampledOPMStratumData = []\n",
    "        for j in range(0,len(StratSampleSize)):\n",
    "            SEP = StratSampleSize[\"SEP\"].ix[j]\n",
    "            DATECODE = StratSampleSize[\"DATECODE\"].ix[j]\n",
    "            AGELVL = StratSampleSize[\"AGELVL\"].ix[j]\n",
    "            SampleSize = StratSampleSize[\"StratSampleSize\"].ix[j]\n",
    "            print(SEP, DATECODE, AGELVL, SampleSize)\n",
    "            \n",
    "            SampledOPMStratumDataList.append(OPMDataMerged[(OPMDataMerged[\"SEP\"]==SEP) \n",
    "                                                    & (OPMDataMerged[\"DATECODE\"]==DATECODE) \n",
    "                                                    & (OPMDataMerged[\"AGELVL\"]==AGELVL)].sample(SampleSize))\n",
    "        SampledOPMStratumData.append(pd.concat(SampledOPMStratumDataList))\n",
    "        clear_display()\n",
    "    SampledOPMData = pd.concat(SampledOPMStratumData).reset_index()\n",
    "    del SampledOPMData[\"index\"]\n",
    "    pickleObject(SampledOPMData, \"SampledOPMData\")\n",
    "    clear_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SampledOPMData))\n",
    "display(SampledOPMData.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "display(pd.DataFrame({'StratCount' : SampledOPMData.groupby([\"SEP\"]).size()}).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#### Analyze Missing Values\n",
    "filtered_msnoData = msno.nullity_sort(msno.nullity_filter(SampledOPMData, filter='bottom', n=15, p=0.999), sort='descending')\n",
    "msno.matrix(filtered_msnoData)\n",
    "\n",
    "del filtered_msnoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "display(SampledOPMData.describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#OPMDataMerged.to_csv(\"OPMDataMerged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.path.getsize(\"OPMDataMerged.csv\") #Display file size in bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "cols = [\"SEP\",\n",
    "        \"SALARY\",\n",
    "        \"LOS\",\n",
    "        \"SEPCount_EFDATE_OCC\",\n",
    "        \"SEPCount_EFDATE_LOC\",\n",
    "        \"IndAvgSalary\",\n",
    "        \"SalaryOverUnderIndAvg\",\n",
    "        \"BLS_FEDERAL_OtherSep_Rate\",\n",
    "        \"BLS_FEDERAL_Quits_Rate\",\n",
    "        \"BLS_FEDERAL_TotalSep_Level\",\n",
    "        \"BLS_FEDERAL_JobOpenings_Rate\",\n",
    "        \"BLS_FEDERAL_OtherSep_Level\",\n",
    "        \"BLS_FEDERAL_Quits_Level\",\n",
    "        \"BLS_FEDERAL_JobOpenings_Level\",\n",
    "        \"BLS_FEDERAL_Layoffs_Rate\",\n",
    "        \"BLS_FEDERAL_Layoffs_Level\",\n",
    "        \"BLS_FEDERAL_TotalSep_Rate\"]\n",
    "\n",
    "plotValid = SampledOPMData[cols].dropna()\n",
    "display(plotValid.head())\n",
    "print(\"PlotValid Has {0} Records\".format(len(plotValid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sns.set()\n",
    "sns.pairplot(plotValid, hue = 'SEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Function modified from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n",
    "sns.set()\n",
    "\n",
    "def draw_histograms(df, variables, n_rows, n_cols):\n",
    "    fig=plt.figure(figsize=(20,20))\n",
    "    for i, var_name in enumerate(variables):\n",
    "        ax=fig.add_subplot(n_rows,n_cols,i+1)\n",
    "        df[var_name].hist(bins=20,ax=ax, color='#58D68D')\n",
    "        ax.set_title(var_name+\" Distribution\")\n",
    "    fig.tight_layout()  # Improves appearance a bit.\n",
    "    plt.show()\n",
    "\n",
    "draw_histograms(plotValid.drop('SEP', axis=1), plotValid.drop('SEP', axis=1).columns, 6, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Inspired by http://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "\n",
    "#plt.matshow(plotValid.corr())\n",
    "\n",
    "sns.set(style='white')\n",
    "corr = plotValid.drop(['SEP'], axis=1).corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask, k=1)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(250, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1,\n",
    "            square=True, annot=True, linewidths=1,\n",
    "            cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "\n",
    "#sns.heatmap(corr, annot=True, linewidths=0.01, cmap=cmap, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Log Transform Columns Added\n",
    "SampledOPMData[\"SALARYLog\"] = SampledOPMData[\"SALARY\"].apply(np.log)\n",
    "SampledOPMData[\"LOSLog\"] = SampledOPMData[\"LOS\"].apply(np.log)\n",
    "SampledOPMData[\"SEPCount_EFDATE_OCCLog\"] = SampledOPMData[\"SEPCount_EFDATE_OCC\"].apply(np.log)\n",
    "SampledOPMData[\"SEPCount_EFDATE_LOCLog\"] = SampledOPMData[\"SEPCount_EFDATE_LOC\"].apply(np.log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
