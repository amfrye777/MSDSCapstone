{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPM Data Separation Analysis\n",
    "<i><b>\n",
    "Christopher Boomhower<sub>1</sub>, Stacey Fabricant<sub>2</sub>, Alex Frye<sub>1</sub>, David Mumford<sub>2</sub>, Michael Smith<sub>1</sub>, Lindsay Vitovsky<sub>1</sub>\n",
    "\n",
    "<sub>1</sub> Southern Methodis Univeristy, Dallas, TX, US\n",
    "<sub>2</sub> Penn Mutual Life Insurance Co, Horsham PA\n",
    "</i></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "background text...\n",
    "\n",
    "**our intent is to: 1)..2)...3)........**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "Data Source Background Text & citation links\n",
    "\n",
    "Dataset Attribute Descriptions\n",
    "(e.g. 1. **tripduration** - *Integer* - The total tim....)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "\n",
    "text intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import missingno as msno\n",
    "import prettytable\n",
    "\n",
    "## Library Options\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pre-defined Functions for use later\n",
    "def pickleObject(objectname, filename, filepath = \"PickleJar/\"):\n",
    "    fullpicklepath = \"{0}{1}.pkl\".format(filepath, filename)\n",
    "    # Create a variable to pickle and open it in write mode\n",
    "    picklefile = open(fullpicklepath, 'wb')\n",
    "    pickle.dump(objectname, picklefile)\n",
    "    picklefile.close()\n",
    "    \n",
    "def unpickleObject(filename, filepath = \"PickleJar/\"):\n",
    "    fullunpicklepath = \"{0}{1}.pkl\".format(filepath, filename)\n",
    "    # Create an variable to pickle and open it in write mode\n",
    "    unpicklefile = open(fullunpicklepath, 'rb')\n",
    "    unpickleObject = pickle.load(unpicklefile)\n",
    "    unpicklefile.close()\n",
    "\n",
    "    return unpickleObject\n",
    "    \n",
    "def clear_display():\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "## Pre-defined variables for use later\n",
    "dataOPMPath = \"dataOPM\"\n",
    "dataEMPPath = \"dataEMP\"\n",
    "PickleJarPath = \"PickleJar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Load OPMSeparation Files\n",
    "\n",
    "OPMDataFiles = glob.glob(os.path.join(dataOPMPath, \"*.txt\"))\n",
    "\n",
    "for i in range(0,len(OPMDataFiles)):\n",
    "    OPMDataFiles[i] = OPMDataFiles[i].replace(\"\\\\\",\"/\")\n",
    "\n",
    "OPMDataList = []\n",
    "\n",
    "for i,j in zip(OPMDataFiles,range(0,len(OPMDataFiles))):\n",
    "    OPMDataList.append(pd.read_csv(i, dtype = 'str'))\n",
    "    display(OPMDataList[j].head())\n",
    "\n",
    "## Load the SEPDATA_FY2015 file into it's own object\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/SEPDATA_FY2015.txt']\n",
    "OPMDataOrig = OPMDataList[indexes[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#print(OPMDataFiles)\n",
    "\n",
    "print(len(OPMDataOrig))\n",
    "\n",
    "##### Merge / Modify Codes / Aggregate Attributes to be more descriptive per the metadata files\n",
    "\n",
    "OPMDataMerged = OPMDataOrig.copy()\n",
    "\n",
    "##AGYSUB - AGYTYP, AGY\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTagy.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'AGYSUB', how = 'left')\n",
    "\n",
    "##EFDate - quarter, month\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTefdate.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'EFDATE', how = 'left')\n",
    "\n",
    "##AGELVL - AGELVLT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTagelvl.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'AGELVL', how = 'left')\n",
    "\n",
    "##LOSLVL - LOSLVLT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTloslvl.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'LOSLVL', how = 'left')\n",
    "\n",
    "##LOC - LocTypeT, LocT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTloc.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'LOC', how = 'left')\n",
    "\n",
    "##OCC - OCCTYPT, OCCFAM\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTocc.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'OCC', how = 'left')\n",
    "\n",
    "##PATCO - PATCOT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTpatco.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'PATCO', how = 'left')\n",
    "\n",
    "##PPGRD - PayPlan, PPGroup, PPTYP\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTppgrd.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'PPGRD', how = 'left')\n",
    "\n",
    "##SALLVL - SALLVLT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTsallvl.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'SALLVL', how = 'left')\n",
    "\n",
    "##TOA - TOATYP\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTtoa.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'TOA', how = 'left')\n",
    "\n",
    "##WORKSCH - WSTYPT\n",
    "indexes = [i for i,x in enumerate(OPMDataFiles) if x == 'dataOPM/DTwrksch.txt']\n",
    "OPMDataMerged = OPMDataMerged.merge(OPMDataList[indexes[0]], on = 'WORKSCH', how = 'left')\n",
    "\n",
    "OPMDataMerged[\"SALARY\"] = OPMDataMerged[\"SALARY\"].apply(pd.to_numeric)\n",
    "display(OPMDataMerged.head())\n",
    "#del OPMDataList,OPMDataFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isfile(PickleJarPath+\"/EMPDataOrig4Q.pkl\"):\n",
    "    print(\"Found the File! Loading Pickle Now!\")\n",
    "    EMPDataOrig4Q = unpickleObject(\"EMPDataOrig4Q\")\n",
    "else:\n",
    "    ## Load EMPData Files\n",
    "\n",
    "    indexes = []\n",
    "    EMPDataFiles = []\n",
    "    EMPDataList = []\n",
    "    EMPDataOrig = []\n",
    "\n",
    "    for i,qtr in enumerate([\"Q1\", \"Q2\", \"Q3\", \"Q4\"]): \n",
    "        EMPDataFiles.append(glob.glob(os.path.join(dataEMPPath, qtr + \"/*.txt\")))\n",
    "\n",
    "        for j in range(0,len(EMPDataFiles[i])):\n",
    "            EMPDataFiles[i][j] = EMPDataFiles[i][j].replace(\"\\\\\",\"/\")\n",
    "\n",
    "        EMPDataList.append([])\n",
    "\n",
    "        for j,file in enumerate(EMPDataFiles[i]):\n",
    "            EMPDataList[i].append(pd.read_csv(file, dtype = 'str'))\n",
    "            if i == 0:\n",
    "                display(EMPDataList[i][j].head())\n",
    "\n",
    "        ## Load the FactData files into it's own object\n",
    "        indexes.append([])\n",
    "            ##[qtr][fileindex from EMPDataList]\n",
    "        indexes[i]=[j for j,x in enumerate(EMPDataFiles[i]) if dataEMPPath + '/' + qtr + '/FACTDATA' in x]   \n",
    "\n",
    "        EMPDataOrig.append([])\n",
    "\n",
    "        EMPDataOrig[i] = pd.concat([EMPDataList[i][indexes[i][j]] for j in range(0,len(indexes[i]))]) \n",
    "        EMPDataOrig[i][\"QTR\"] = str(i+1)\n",
    "\n",
    "            ## modify data type for salary for aggregation\n",
    "        EMPDataOrig[i][\"SALARY\"] = EMPDataOrig[i][\"SALARY\"].str.replace(',', '').str.replace('$', '').str.replace(' ', '').apply(pd.to_numeric)\n",
    "\n",
    "            ## Load Metadata\n",
    "        ##AGYSUB - AGYTYP, AGY\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTagy.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'AGYSUB', how = 'left')\n",
    "\n",
    "        ##AGELVL - AGELVLT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTagelvl.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'AGELVL', how = 'left')\n",
    "\n",
    "        ##LOSLVL - LOSLVLT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTloslvl.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'LOSLVL', how = 'left')\n",
    "\n",
    "        ##LOC - LocTypeT, LocT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTloc.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'LOC', how = 'left')\n",
    "\n",
    "        ##OCC - OCCTYPT, OCCFAM\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTocc.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'OCC', how = 'left')\n",
    "\n",
    "        ##PATCO - PATCOT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTpatco.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'PATCO', how = 'left')\n",
    "\n",
    "        ##PPGRD - PayPlan, PPGroup, PPTYP\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTppgrd.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'PPGRD', how = 'left')\n",
    "\n",
    "        ##SALLVL - SALLVLT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTsallvl.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'SALLVL', how = 'left')\n",
    "\n",
    "        ##TOA - TOATYP\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTtoa.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'TOA', how = 'left')\n",
    "\n",
    "        ##WORKSCH - WSTYPT\n",
    "        ind2 = [i for i,x in enumerate(EMPDataFiles[i]) if x == dataEMPPath + '/' + qtr + '/DTwrksch.txt']\n",
    "        EMPDataOrig[i] = EMPDataOrig[i].merge(EMPDataList[i][ind2[0]], on = 'WORKSCH', how = 'left')\n",
    "\n",
    "        display(EMPDataOrig[i].head())\n",
    "\n",
    "    EMPDataOrig4Q = pd.concat([EMPDataOrig[j] for j in range(0,len(EMPDataOrig))])\n",
    "    pickleObject(EMPDataOrig4Q, \"EMPDataOrig4Q\")\n",
    "\n",
    "print(len(EMPDataOrig4Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(EMPDataOrig4Q.describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.boxplot(y = \"SALARY\", data = EMPDataOrig4Q)\n",
    "#sns.boxplot(y = \"QTR\", data = EMPDataOrig4Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "##Aggregate Number of Total Separations in current month for given Occ\n",
    "Agg = pd.DataFrame({'SEPCount_EFDATE_OCC' : OPMDataMerged.groupby([\"EFDATE\", \"OCC\"]).size()}).reset_index()\n",
    "display(Agg.head())\n",
    "OPMDataMerged = OPMDataMerged.merge(Agg, on = ['EFDATE','OCC'], how = 'left')\n",
    "EMPDataOrig4Q = EMPDataOrig4Q.merge(Agg, left_on = ['DATECODE','OCC'], right_on = ['EFDATE','OCC'], how = 'left')\n",
    "\n",
    "##Aggregate Number of Total Separations in current month for given LOC\n",
    "Agg = pd.DataFrame({'SEPCount_EFDATE_LOC' : OPMDataMerged.groupby([\"EFDATE\", \"LOC\"]).size()}).reset_index()\n",
    "display(Agg.head())\n",
    "OPMDataMerged = OPMDataMerged.merge(Agg, on = ['EFDATE','LOC'], how = 'left')\n",
    "EMPDataOrig4Q = EMPDataOrig4Q.merge(Agg, left_on = ['DATECODE','LOC'], right_on = ['EFDATE','LOC'], how = 'left')\n",
    "\n",
    "##Average Quarterly EMP Salary by occ \n",
    "Agg = pd.DataFrame({'count' : EMPDataOrig4Q.groupby([\"QTR\", \"OCC\"]).size()}).reset_index()\n",
    "Agg2 = pd.DataFrame({'IndSalarySum' : EMPDataOrig4Q.groupby([\"QTR\", \"OCC\"])[\"SALARY\"].sum()}).reset_index()\n",
    "Agg = Agg.merge(Agg2,on=[\"QTR\", \"OCC\"])\n",
    "Agg[\"IndAvgSalary\"] = Agg[\"IndSalarySum\"]/Agg[\"count\"]\n",
    "\n",
    "del Agg[\"count\"]\n",
    "del Agg[\"IndSalarySum\"]\n",
    "\n",
    "display(Agg.head())\n",
    "\n",
    "OPMDataMerged = OPMDataMerged.merge(Agg, on = ['QTR','OCC'], how = 'left')\n",
    "EMPDataOrig4Q = EMPDataOrig4Q.merge(Agg, on = ['QTR','OCC'], how = 'left')\n",
    "\n",
    "\n",
    "display(OPMDataMerged.head())\n",
    "display(EMPDataOrig4Q.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(OPMDataMerged.tail())\n",
    "display(EMPDataOrig4Q.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#### Analyze Missing Values\n",
    "#use missingno here\n",
    "filtered_msnoData = msno.nullity_filter(OPMDataMerged, filter='bottom', n=10, p=0.999)\n",
    "msno.matrix(filtered_msnoData.sample(50000))\n",
    "\n",
    "filtered_msnoData = msno.nullity_filter(EMPDataOrig4Q, filter='bottom', n=10, p=0.999)\n",
    "msno.matrix(filtered_msnoData.sample(50000))\n",
    "\n",
    "del filtered_msnoData\n",
    "#### Fix Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "display(OPMDataMerged.describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Bureau of Labor Statistics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def bls(series, start, end):\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data = json.dumps({\"seriesid\": series,\n",
    "                       \"startyear\":start,\n",
    "                       \"endyear\":end,\n",
    "                       \"catalog\":False,\n",
    "                       \"calculations\":False,\n",
    "                       \"annualaverage\":False,\n",
    "                       \"registrationkey\":\"7a89c8d7979349fba8914b8be16a1646\"})\n",
    "    \n",
    "    p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "    json_data = json.loads(p.text)\n",
    "    bls = []\n",
    "    for series in json_data['Results']['series']:\n",
    "        #x=prettytable.PrettyTable([\"series id\",\"year\",\"period\",\"value\",\"footnotes\"])\n",
    "        result = pd.DataFrame(columns=[\"series id\",\"year\",\"period\",\"value\",\"footnotes\"])\n",
    "        seriesId = series['seriesID']\n",
    "        for item in series['data']:\n",
    "            year = item['year']\n",
    "            period = item['period']\n",
    "            value = item['value']\n",
    "            footnotes=\"\"\n",
    "            for footnote in item['footnotes']:\n",
    "                if footnote:\n",
    "                    footnotes = footnotes + footnote['text'] + ','\n",
    "            if 'M01' <= period <= 'M12':\n",
    "                #x.add_row([seriesId,year,period,value,footnotes[0:-1]])\n",
    "                y = pd.DataFrame({\"series id\" : seriesId,\n",
    "                                  \"year\" : year,\n",
    "                                  \"period\" : period,\n",
    "                                  \"value\" : value,\n",
    "                                  \"footnotes\" : footnotes}, index = [0])\n",
    "                result = result.append(y, ignore_index = True)\n",
    "                #x.concat([seriesId,year,period,value,footnotes[0:-1]], ignore_index=True)\n",
    "        #result = x.append(y)\n",
    "        bls.append(result)\n",
    "    return(bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test=pd.DataFrame(columns=[\"series id\",\"year\",\"period\",\"value\",\"footnotes\"])\n",
    "##test2 = pd.DataFrame([3,2012,'M12',132,'dude'], columns=[\"series id\",\"year\",\"period\",\"value\",\"footnotes\"]).T\n",
    "#test2 = pd.DataFrame({\"series id\" : 3, \"year\" : 2012, \"period\" : 'M12', \"value\" : 132, \"footnotes\" : 'dude'}, index = [0])\n",
    "#test3 = pd.DataFrame({\"series id\" : 4, \"year\" : 2011, \"period\" : 'M11', \"value\" : 135, \"footnotes\" : 'dude2'}, index = [0])\n",
    "##result = pd.append([test,test2], axis = 1)\n",
    "#result = test.append([test2, test3], ignore_index = True)\n",
    "#display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Pull job openings and labor turnover data\n",
    "JTL = bls(['JTU91000000HIL',\n",
    "     'JTU91000000JOL',\n",
    "     'JTU91000000LDL',\n",
    "     'JTU91000000OSL',\n",
    "     'JTU91000000QUL',\n",
    "     'JTU91000000TSL',\n",
    "     'JTU91000000UNL',\n",
    "     'JTU91000000UOL'], \"2014\", \"2015\")\n",
    "\n",
    "display(JTL[3])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
